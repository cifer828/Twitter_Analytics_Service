{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "import os\n",
    "from pyspark.sql.functions import col, max\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.types import *\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class CSV2SQL:\n",
    "    def __init__(self, local=True, choice=-1):\n",
    "        self.local = local\n",
    "        self.choice = choice\n",
    "        # Choice\n",
    "        # 1 single file\n",
    "        # 0 all files\n",
    "        # -1 test file\n",
    "        prefix = \"file:///Users/qiuchenzhang/Code/CMU/15619/Ying_Liu_Zhi_Zhu-S20/phase1/twitter/ETL/output/\" if local else \"hdfs:///output/\"\n",
    "        self.output = prefix + \"oneOutput/\" if choice == 1 else prefix + \"allOutput/\" if choice == 0 else prefix + \"testOutput/\"\n",
    "        self.table_prefix = \"one_\" if choice == 1 else \"all_\" if choice == 0 else \"test_\"\n",
    "\n",
    "        # specify JAVA_HOME when running locally\n",
    "        if self.local:\n",
    "            os.environ[\"JAVA_HOME\"] = \"/usr/local/opt/jenv/versions/openjdk64-1.8.0.242\"\n",
    "\n",
    "        # get spark session\n",
    "        if local:\n",
    "            self.spark = SparkSession.builder \\\n",
    "                        .master(\"local[*]\") \\\n",
    "                        .appName(\"twitter-local-csv2sql\") \\\n",
    "                        .config(\"spark.some.config.option\", \"SparkSessionExample\") \\\n",
    "                        .getOrCreate()\n",
    "        else:\n",
    "            config = SparkConf().setAll(\n",
    "                [('spark.driver.extraClassPath', '/home/qiuchenzhang/mysql-connector-java-8.0.19.jar'),\n",
    "                 ('spark.jars', '/home/qiuchenzhang/mysql-connector-java-8.0.19.jar'),\n",
    "                 ('spark.driver.userClassPathFirst', True),\n",
    "                 ('spark.executor.userClassPathFirst', True)])\n",
    "            self.spark = SparkSession.builder \\\n",
    "                .master(\"yarn\") \\\n",
    "                .appName(\"twitter-yarn-csv2sql\") \\\n",
    "                .config(conf=config) \\\n",
    "                .getOrCreate()\n",
    "\n",
    "        self.tweet_df = None\n",
    "        self.user_df = None\n",
    "        self.logger = None\n",
    "        self.init_log()\n",
    "\n",
    "    def init_log(self):\n",
    "        # Create and configure logger\n",
    "        now = datetime.now()\n",
    "        logging.basicConfig(filename=\"log/csv2sql-\" + now.strftime(\"%Y-%m-%d-%H-%M-%S\") +\".log\",\n",
    "                            format='%(asctime)s %(message)s',\n",
    "                            filemode='w')\n",
    "        self.logger = logging.getLogger()\n",
    "        # datetime object containing current date and time\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "\n",
    "        if self.local:\n",
    "            self.logger.info(\"\\n*******************\\ncreate spark session locally.\")\n",
    "        else:\n",
    "            self.logger.info(\"\\n*******************\\ncreate spark session on server.\")\n",
    "\n",
    "    def read_df(self):\n",
    "\n",
    "        # Read from intermediate file\n",
    "        tweet_df_file = self.output + \"tweetDf/*.csv\"\n",
    "        tweet_schema = StructType([\n",
    "            StructField(\"tid\", LongType(), False),\n",
    "            StructField(\"timestamp\", LongType(), False),\n",
    "            StructField(\"content\", StringType(), False),\n",
    "            StructField(\"reply_to_uid\", LongType(), True),\n",
    "            StructField(\"sender_uid\", LongType(), False),\n",
    "            StructField(\"retweet_to_uid\", LongType(), True),\n",
    "            StructField(\"hashtags\", StringType(), False),\n",
    "            StructField(\"lang\", StringType(), False)]\n",
    "        )\n",
    "        self.logger.info(\"reading tweet_df from \" + tweet_df_file)\n",
    "        self.tweet_df = self.spark.read.csv(tweet_df_file, sep=\"⊢\", header=True, multiLine=True, schema=tweet_schema)\n",
    "\n",
    "        self.logger.info(\"finish reading tweet_df: \" + str(self.tweet_df.count()) + \" items\")\n",
    "\n",
    "        user_df_file = self.output + \"userDf/*.csv\"\n",
    "        user_schema = StructType([\n",
    "            StructField(\"uid\", LongType(), False),\n",
    "            StructField(\"screen_name\", StringType(), False),\n",
    "            StructField(\"description\", StringType(), False),\n",
    "            StructField(\"timestamp\", LongType(), False)]\n",
    "        )\n",
    "        self.logger.info(\"reading user_df from \" + user_df_file)\n",
    "        self.user_df = self.spark.read.csv(user_df_file, sep=\"⊢\", header=True, multiLine=True, schema=user_schema)\n",
    "        self.logger.info(\"finish reading tweet_df: \" + str(self.tweet_df.count()) + \" items\")\n",
    "\n",
    "    def load2sql(self, db_local=False):\n",
    "        # Load to SQL\n",
    "        # jdbc configuration\n",
    "        jdbcPort = \"3306\"\n",
    "        jdbcDatabase = \"etl_test_db\"\n",
    "        jdbcUsername = \"root\"\n",
    "        jdbcPassword = \"password\"\n",
    "        jdbcHostname = \"localhost\" if db_local else \"35.243.231.47\"\n",
    "\n",
    "        jdbcUrl = \"jdbc:mysql://\" + jdbcHostname + \":\" + jdbcPort + \"/\" + jdbcDatabase + \"?serverTimezone=UTC\"\n",
    "\n",
    "        # write tweet table\n",
    "        self.logger.info(\n",
    "            \"loading tweet_df to \" + jdbcHostname + \"/\" + jdbcDatabase + self.table_prefix + \"tweet_table\")\n",
    "        self.tweet_df.write.format('jdbc').options(\n",
    "            url=jdbcUrl,\n",
    "            driver='com.mysql.cj.jdbc.Driver',\n",
    "            dbtable=self.table_prefix + \"tweet_table\",\n",
    "            user=jdbcUsername,\n",
    "            password=jdbcPassword).mode('overwrite').save()\n",
    "        self.logger.info(\"finish loading tweet_df\")\n",
    "\n",
    "        # write user table\n",
    "        self.logger.info(\n",
    "            \"loading user_df to \" + jdbcHostname + \"/\" + jdbcDatabase + \" as \" + self.table_prefix + \"user_table\")\n",
    "        self.user_df.write.format('jdbc').options(\n",
    "            url=jdbcUrl,\n",
    "            driver='com.mysql.cj.jdbc.Driver',\n",
    "            dbtable=self.table_prefix + \"user_table\",\n",
    "            user=jdbcUsername,\n",
    "            password=jdbcPassword).mode('overwrite').save()\n",
    "        self.logger.info(\"finish loading user_df\")\n",
    "\n",
    "    def unique_user(self):\n",
    "        # remove duplicate users\n",
    "        user_mid_df = self.spark.read.csv(self.output + \"userMidDf/*.csv\", sep=\"⊢\", header=True, multiLine=True, inferSchema=True)\n",
    "        w = Window.partitionBy(col(\"uid\"))\n",
    "        self.user_df = user_mid_df.withColumn(\"latestTime\", max(\"timestamp\").over(w)). \\\n",
    "            filter(col(\"latestTime\") == col(\"timestamp\")). \\\n",
    "            drop(\"timestamp\"). \\\n",
    "            withColumnRenamed(\"latestTime\", \"timestamp\"). \\\n",
    "            dropDuplicates([\"uid\"])\n",
    "        self.logger.info(\n",
    "            \"Created user_df: find the latest information of each users\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # local: run locally or remotely\n",
    "    # choice: 1 single file, 0 all files, -1 test file\n",
    "    csv2sql = CSV2SQL(local=True, choice=1)  # local, test\n",
    "    csv2sql.read_df()\n",
    "    csv2sql.unique_user()\n",
    "    csv2sql.load2sql(db_local=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53971"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python36",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
